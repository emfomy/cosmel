Introduction
============

.. only:: html

   .. image:: https://img.shields.io/badge/Python-3.6-blue.svg
   .. image:: https://img.shields.io/badge/PyTorch-0.4.1-blue.svg

Cosmetic Entity Linking (CosmEL) is an entity linking tool in cosmetic domain.

Author
------

* `CKIP Lab <http://ckip.iis.sinica.edu.tw/>`_, Institute of Information Science, Academia Sinica, Taipei, Taiwan.
   * Mu Yang      <http://muyang.pro>
   * Chi-Yen Chen <jina199312@gmail.com>
   * Yi-Hui Lee   <lilyyhlee30@gmail.com>
   * Wei-Yun Ma   <ma@iis.sinica.edu.tw>

Links
-----

* GitHub https://github.com/emfomy/cosmel
* Documentation https://emfomy.github.io/cosmel-data
* Dataset https://github.com/emfomy/cosmel-data


Requirement
-----------

* Program and Tools
   * `Python <http://www.python.org/>`_ 3.6.
   * `CKIPWS <http://otl.sinica.edu.tw/index.php?t=9&group_id=25&article_id=408>`_ Linux version.
   * `CKIPNLP Python Package <https://ckipnlp.readthedocs.io>`_ 0.6.
* Python Packages
   * `BeautifulSoup <http://www.crummy.com/software/BeautifulSoup/>`_ 4.6.
   * `gensim <https://radimrehurek.com/gensim/>`_ 3.6.
   * `lxml <http://lxml.de/>`_ 4.2.
   * `NumPy <http://numpy.scipy.org/>`_ 1.15.
   * `PyTorch <http://pytorch.org/>`_ 0.4.1.
   * `scikit-learn <http://scikit-learn.org/>`_ 0.20.
   * `tqdm <https://pypi.org/project/tqdm/>`_ 4.27.
* Documentation Packages (Optional)
   * `sphinx <http://www.sphinx-doc.org/>`_ 1.8.5.
   * `sphinx_rtd_theme <https://github.com/rtfd/sphinx_rtd_theme/>`_ 0.4.3.
   * `sphinxcontrib-programoutput <https://bitbucket.org/birkenfeld/sphinx-contrib>`_ 0.15.


About
-----

Cosmetic Entity Linking (CosmEL) is an entity linking tool in cosmetic domain. We train a entity linking model from given articles with manually labeling. Usually, it is inefficient to manually label all the mentions. We provide several decision-tree-based rules with laboriously observation, and train the entity linking model by using the labeled data automatically generated by the rule with a small amount of manual labeled data.


Flow Chart
----------

We split our progress in to four parts:

   Database Generation
      Generates the database (including the information of brands and products) from raw CSV data.

      .. seealso::

         * Specification - :ref:`SpecUtilDatabaseGeneration`
         * Quick Start - :ref:`QuickStartDatabaseGeneration`

   Corpus Generation
      Creates the corpus from articles in plain text. This step exports the rule-labeled articles.
      Please manually label the XML files to create golden labeled articles.

      .. image:: ../_static/flowchart/flowchart.001.png

      .. seealso::

         * Specification - :ref:`SpecToolCorpusGeneration`
         * Quick Start - :ref:`QuickStartTraining`
         * Quick Start - :ref:`QuickStartPrediction`

   Training
      Trains the model using rule-labeled articles and golden labeled articles.

      .. image:: ../_static/flowchart/flowchart.002.png

      .. seealso::

         * Specification - :ref:`SpecToolTraining`
         * Quick Start - :ref:`QuickStartTraining`

   Prediction
      Predicts the mention labels using the model.

      .. image:: ../_static/flowchart/flowchart.003.png

      .. seealso::

         * Specification - :ref:`SpecToolPrediction`
         * Quick Start - :ref:`QuickStartPrediction`


.. _SectionQuickStart:

Quick Start
===========

Installation
------------

One may install using either pip or Conda.

Install with pip
^^^^^^^^^^^^^^^^

.. code-block:: bash

   pip install torch==0.4.1 torchvision
   pip install beautifulsoup4==4.6 gensim==3.6 lxml==4.2 numpy==1.15 scikit-learn==0.20 tqdm==4.27

Install with Conda
^^^^^^^^^^^^^^^^^^

First install the Conda environment. Conda is an open source package management system. It quickly installs, runs and updates packages and their dependencies.

.. code-block:: bash

   wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
   sh ./Miniconda3-latest-Linux-x86_64.sh

Make sure to prepend the Miniconda3 install location to ``PATH`` in your ``.bashrc``. Now restart your shell to enable ``PATH``, or export it manually:

.. code-block:: bash

   export PATH="$HOME/miniconda3/bin:$PATH"

Next, create a new Conda environment for CosmEL, named **cosmel**, with Python version 3.6.

.. code-block:: bash

   conda create -n cosmel python=3.6


Install Packages
""""""""""""""""

First activate the CosmEL Conda environment:

.. code-block:: bash

   source activate cosmel

Now, ``(cosmel)`` will be appended to the prompt string:

.. code-block:: console

   (cosmel) <user>@<host>:~$

Next, install the Python packages:

.. code-block:: bash

   conda install pytorch=0.4.1 -c pytorch
   conda install beautifulsoup4=4.6 gensim=3.4 lxml=4.2 numpy=1.15 scikit-learn=0.20 tqdm=4.26


CKIPWS
^^^^^^

Please install the `CKIPNLP Python Package <https://ckipnlp.readthedocs.io>`_.

Denote the root path of CKIPWS as ``<ckipws-linux-root>``.

.. code-block:: bash

   pip install --upgrade ckipnlp
   pip install --no-deps --force-reinstall --upgrade ckipnlp \
      --install-option='--ws' \
      --install-option='--ws-dir=<ckipws-linux-root>'

Example
-------

First, goto the root path of CosmEL (``<cosmel-root>``, the folder containing this README), and create the working space for this example (``data/demo/``).

.. code-block:: bash

   cd <cosmel-root>
   mkdir -p data/demo


.. _QuickStartDatabaseGeneration:

Database Generation
^^^^^^^^^^^^^^^^^^^

Generate database from ``demo/styleme.csv``:

.. code-block:: bash

   python3 ./util/database_generate.py -i demo/styleme.csv -d data/demo/repo

You can modify ``data/demo/repo/etc/`` to ameliorate the database.

You may also use the predefined database by adding ``--etc``:

.. code-block:: bash

   python3 ./util/database_generate.py -i demo/styleme.csv -d data/demo/repo --etc

The database are stored in ``data/demo/repo/``.


.. seealso::

   * Notes - :ref:`NoteDatabaseGeneration`
   * Specification - :ref:`SpecUtilDatabaseGeneration`
   * Data Structure - :ref:`XMLFormat`


.. _QuickStartTraining:

Training
^^^^^^^^

In training step, first generate the corpus (``data/demo/corpus1/``) from the articles (``demo/original_article1/``). Here ``demo/repo/`` is used as database.

.. code-block:: bash

   python3 ./tool/corpusgen.py -c data/demo/corpus1 -d demo/repo -i demo/original_article1 -x data/demo/output/rid1  -X data/demo/output/nil1

The rule-labeled articles are exported to ``data/demo/output/rid1/``, and the empty XML articles are exported to ``data/demo/output/nil1/``. You may modify the ``gid`` flags in the empty XML articles for manually annotation. (For HTML format, please refer :ref:`SpecUtilHTMLEncoding` and :ref:`SpecUtilHTMLDecoding`)

Next, you may train word embeddings from the corpus (stored in ``data/demo/corpus1/embeddings/``):

.. code-block:: bash

   python3 ./util/word2vec.py -c data/demo/corpus1


Or use other embeddings, but make sure that all brand aliases are contained in this embeddings.

Finally, train the model using the corpus (``data/demo/corpus1/``), with manually-labeled articles ``demo/purged_article_gid_xml1/`` and embeddings file ``demo/emb1.bin``:

.. code-block:: bash

   python3 ./tool/train.py -c data/demo/corpus1 -m data/demo/model1 -x demo/purged_article_gid_xml1 --emb demo/emb1.bin

The model data are stored in ``data/demo/model1/``.

.. seealso::

   * Specification - :ref:`SpecToolCorpusGeneration`
   * Specification - :ref:`SpecUtilWord2Vec`
   * Specification - :ref:`SpecToolTraining`


.. _QuickStartPrediction:

Prediction
^^^^^^^^^^

In prediction step, first generate the corpus (``data/demo/corpus2/``) from the articles (``demo/original_article2/``). Here ``demo/repo/`` is used as database.

.. code-block:: bash

   python3 ./tool/corpusgen.py -c data/demo/corpus2 -d demo/repo -i demo/original_article2

Next, predict the labels of the corpus (``data/demo/corpus2/``) with model ``data/demo/model1/``.

.. code-block:: bash

   python3 ./tool/predict.py -c data/demo/corpus2 -m data/demo/model1 -o data/demo/output/nid2

The results are exported to ``data/demo/output/nid2/``.

.. seealso::

   * Specification - :ref:`SpecToolCorpusGeneration`
   * Specification - :ref:`SpecToolPrediction`


Documentation
-------------

To build the documentation, please install the following packages.

(Using pip)

.. code-block:: bash

   pip install sphinx==1.8.1 sphinx_rtd_theme==0.4.2 sphinxcontrib-programoutput==0.11

(Using Conda)

.. code-block:: bash

   conda install sphinx=1.8.1 sphinx_rtd_theme=0.4.2
   conda install sphinxcontrib-programoutput=0.11 -c conda-forge

Next, build the HTML documentation.

.. code-block:: bash

   cd <cosmel-root>/docs
   make html

The outputs are located in ``<cosmel-root>/docs/_build/html/``.

You may also build PDF documentation using LaTeX if you have ``latexmk`` and ``xelatex`` installed.

.. code-block:: bash

   make latex

The outputs are located in ``<cosmel-root>/docs/_build/latex/``.
